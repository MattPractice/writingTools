{"cells": [{"cell_type": "code", "execution_count": null, "id": "import-spacy-requests", "metadata": {}, "outputs": [], "source": ["!pip install spacy requests\n", "!python -m spacy download en_core_web_sm"]}, {"cell_type": "code", "execution_count": null, "id": "import-libraries", "metadata": {}, "outputs": [], "source": ["# Import the necessary libraries\n", "import spacy\n", "import requests"]}, {"cell_type": "code", "execution_count": null, "id": "load-model", "metadata": {}, "outputs": [], "source": ["# Load the pre-trained English model\n", "nlp = spacy.load('en_core_web_sm')"]}, {"cell_type": "code", "execution_count": null, "id": "download-text", "metadata": {}, "outputs": [], "source": ["def download_text(url):\n", "    \"\"\"\n", "    Download text from the given URL.\n", "\n", "    Parameters:\n", "    url (str): The URL to download the text from.\n", "\n", "    Returns:\n", "    str: The downloaded text.\n", "    \"\"\"\n", "    response = requests.get(url)\n", "    response.raise_for_status()  # Ensure we notice bad responses\n", "    return response.text"]}, {"cell_type": "code", "execution_count": null, "id": "define-extract-entities", "metadata": {}, "outputs": [], "source": ["def extract_entities(text):\n", "    \"\"\"\n", "    Extract entities from the given text using spaCy.\n", "\n", "    Parameters:\n", "    text (str): The text from which to extract entities.\n", "\n", "    Returns:\n", "    list: A list of tuples where each tuple contains the entity text and its label.\n", "    \"\"\"\n", "    # Process the text with the spaCy model\n", "    doc = nlp(text)\n", "\n", "    # Extract entities\n", "    entities = [(entity.text, entity.label_) for entity in doc.ents]\n", "\n", "    return entities"]}, {"cell_type": "code", "execution_count": null, "id": "example-usage", "metadata": {}, "outputs": [], "source": ["# Example usage\n", "if __name__ == \"__main__\":\n", "    url = \"http://www.gutenberg.org/files/1342/1342-0.txt\"  # Example URL for \"Pride and Prejudice\"\n", "    text = download_text(url)\n", "    entities = extract_entities(text[:10000])  # Process only the first 10,000 characters for demo purposes\n", "    print(\"Entities found:\", entities)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 5}